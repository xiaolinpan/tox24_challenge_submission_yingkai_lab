{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "03568baa-4d77-4357-8ebd-91bb9565f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load siamese_network_fine_tuning.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os, sys\n",
    "sys.path.append(\"./sPhysNet-MT/\")\n",
    "\n",
    "from Networks.PhysDimeNet import PhysDimeNet\n",
    "from utils.utils_functions import fix_model_keys\n",
    "from torch.nn import Module\n",
    "from torch.optim.swa_utils import AveragedModel\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch_geometric\n",
    "from torch_geometric.loader import DataLoader\n",
    "from ase.units import Hartree, eV, kcal\n",
    "from scipy.spatial import Voronoi\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "import os\n",
    "import pandas as pd\n",
    "from openbabel import pybel\n",
    "\n",
    "\n",
    "hartree2ev = Hartree / eV\n",
    "\n",
    "_force_cpu = False\n",
    "\n",
    "ev2hartree = eV / Hartree\n",
    "\n",
    "\n",
    "def get_coords(pmol):\n",
    "    coords = []\n",
    "    for atom in pmol.atoms:\n",
    "        coords.append(atom.coords)\n",
    "    return np.array(coords)\n",
    "\n",
    "def get_elements(pmol):\n",
    "    z = []\n",
    "    for atom in pmol.atoms:\n",
    "        z.append(atom.atomicnum)\n",
    "    return np.array(z)\n",
    "\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# def get_device():\n",
    "#     return torch.device(\"cpu\")\n",
    "\n",
    "def set_force_cpu():\n",
    "    \"\"\"\n",
    "    ONLY use it when pre-processing data\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global _force_cpu\n",
    "    _force_cpu = True\n",
    "\n",
    "\n",
    "def _get_index_from_matrix(num, previous_num):\n",
    "    \"\"\"\n",
    "    get the fully-connect graph edge index compatible with torch_geometric message passing module\n",
    "    eg: when num = 3, will return:\n",
    "    [[0, 0, 0, 1, 1, 1, 2, 2, 2]\n",
    "    [0, 1, 2, 0, 1, 2, 0, 1, 2]]\n",
    "    :param num:\n",
    "    :param previous_num: the result will be added previous_num to fit the batch\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    index = torch.LongTensor(2, num * num)\n",
    "    index[0, :] = torch.cat([torch.zeros(num).long().fill_(i) for i in range(num)], dim=0)\n",
    "    index[1, :] = torch.cat([torch.arange(num).long() for __ in range(num)], dim=0)\n",
    "    mask = (index[0, :] != index[1, :])\n",
    "    return index[:, mask] + previous_num\n",
    "\n",
    "\n",
    "def cal_edge(R, N, prev_N, edge_index, cal_coulomb=True, short_range=True):\n",
    "    \"\"\"\n",
    "    calculate edge distance from edge_index;\n",
    "    if cal_coulomb is True, additional edge will be calculated without any restriction\n",
    "    :param short_range:\n",
    "    :param cal_coulomb:\n",
    "    :param prev_N:\n",
    "    :param edge_index:\n",
    "    :param R:\n",
    "    :param N:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if cal_coulomb:\n",
    "        '''\n",
    "        IMPORTANT: DO NOT use num(tensor) itself as input, which will be regarded as dictionary key in this function,\n",
    "        use int value(num.item())\n",
    "        Using tensor as dictionary key will cause unexpected problem, for example, memory leak\n",
    "        '''\n",
    "        coulomb_index = torch.cat(\n",
    "            [_get_index_from_matrix(num.item(), previous_num) for num, previous_num in zip(N, prev_N)], dim=-1)\n",
    "        points1 = R[coulomb_index[0, :], :]\n",
    "        points2 = R[coulomb_index[1, :], :]\n",
    "        coulomb_dist = torch.sum((points1 - points2) ** 2, keepdim=True, dim=-1)\n",
    "        coulomb_dist = torch.sqrt(coulomb_dist)\n",
    "\n",
    "    else:\n",
    "        coulomb_dist = None\n",
    "        coulomb_index = None\n",
    "\n",
    "    if short_range:\n",
    "        short_range_index = edge_index\n",
    "        points1 = R[edge_index[0, :], :]\n",
    "        points2 = R[edge_index[1, :], :]\n",
    "        short_range_dist = torch.sum((points1 - points2) ** 2, keepdim=True, dim=-1)\n",
    "        short_range_dist = torch.sqrt(short_range_dist)\n",
    "    else:\n",
    "        short_range_dist, short_range_index = None, None\n",
    "    return coulomb_dist, coulomb_index, short_range_dist, short_range_index\n",
    "\n",
    "\n",
    "def scale_R(R):\n",
    "    abs_min = torch.abs(R).min()\n",
    "    while abs_min < 1e-3:\n",
    "        R = R - 1\n",
    "        abs_min = torch.abs(R).min()\n",
    "    return R\n",
    "\n",
    "\n",
    "def cal_msg_edge_index(edge_index):\n",
    "    msg_id_1 = torch.arange(edge_index.shape[-1]).repeat(edge_index.shape[-1], 1)\n",
    "    msg_id_0 = msg_id_1.t()\n",
    "    source_atom = edge_index[0, :].repeat(edge_index.shape[-1], 1)\n",
    "    target_atom = edge_index[1, :].view(-1, 1)\n",
    "    msg_map = (source_atom == target_atom)\n",
    "    result = torch.cat([msg_id_0[msg_map].view(1, -1), msg_id_1[msg_map].view(1, -1)], dim=0)\n",
    "    return result\n",
    "\n",
    "\n",
    "def voronoi_edge_index(R, boundary_factor, use_center):\n",
    "    \"\"\"\n",
    "    Calculate Voronoi Diagram\n",
    "    :param R: shape[-1, 3], the location of input points\n",
    "    :param boundary_factor: Manually setup a boundary for those points to avoid potential error, value of [1.1, inf]\n",
    "    :param use_center: If true, the boundary will be centered on center of points; otherwise, boundary will be centered\n",
    "    on [0., 0., 0.]\n",
    "    :return: calculated edge idx_name\n",
    "    \"\"\"\n",
    "    R = scale_R(R)\n",
    "\n",
    "    R_center = R.mean(dim=0) if use_center else torch.DoubleTensor([0, 0, 0])\n",
    "\n",
    "    # maximum relative coordinate\n",
    "    max_coordinate = torch.abs(R - R_center).max()\n",
    "    boundary = max_coordinate * boundary_factor\n",
    "    appended_R = torch.zeros(8, 3).double().fill_(boundary)\n",
    "    idx = 0\n",
    "    for x_sign in [-1, 1]:\n",
    "        for y_sign in [-1, 1]:\n",
    "            for z_sign in [-1, 1]:\n",
    "                appended_R[idx] *= torch.DoubleTensor([x_sign, y_sign, z_sign])\n",
    "                idx += 1\n",
    "    num_atoms = R.shape[0]\n",
    "\n",
    "    appended_R = appended_R + R_center\n",
    "    diagram = Voronoi(torch.cat([R, appended_R], dim=0), qhull_options=\"Qbb Qc Qz\")\n",
    "    edge_one_way = diagram.ridge_points\n",
    "    edge_index_all = torch.LongTensor(np.concatenate([edge_one_way, edge_one_way[:, [1, 0]]], axis=0)).t()\n",
    "    mask0 = edge_index_all[0, :] < num_atoms\n",
    "    mask1 = edge_index_all[1, :] < num_atoms\n",
    "    mask = mask0 & mask1\n",
    "    edge_index = edge_index_all[:, mask]\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "\n",
    "def sort_edge(edge_index):\n",
    "    \"\"\"\n",
    "    sort the target of edge to be sequential, which may increase computational efficiency later on when training\n",
    "    :param edge_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    arg_sort = torch.argsort(edge_index[1, :])\n",
    "    return edge_index[:, arg_sort]\n",
    "\n",
    "\n",
    "def mol_to_edge_index(mol):\n",
    "    \"\"\"\n",
    "    Calculate edge_index(bonding edge) from rdkit.mol\n",
    "    :param mol:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    bonds = mol.GetBonds()\n",
    "    num_bonds = len(bonds)\n",
    "    _edge_index = torch.zeros(2, num_bonds).long()\n",
    "    for bond_id, bond in enumerate(bonds):\n",
    "        _edge_index[0, bond_id] = bond.GetBeginAtomIdx()\n",
    "        _edge_index[1, bond_id] = bond.GetEndAtomIdx()\n",
    "    _edge_index_inv = _edge_index[[1, 0], :]\n",
    "    _edge_index = torch.cat([_edge_index, _edge_index_inv], dim=-1)\n",
    "    return _edge_index\n",
    "\n",
    "\n",
    "def remove_bonding_edge(all_edge_index, bond_edge_index):\n",
    "    \"\"\"\n",
    "    Remove bonding idx_name from atom_edge_index to avoid double counting\n",
    "    :param all_edge_index:\n",
    "    :param bond_edge_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    mask = torch.zeros(all_edge_index.shape[-1]).bool().fill_(False).type(all_edge_index.type())\n",
    "    len_bonding = bond_edge_index.shape[-1]\n",
    "    for i in range(len_bonding):\n",
    "        same_atom = (all_edge_index == bond_edge_index[:, i].view(-1, 1))\n",
    "        mask += (same_atom[0] & same_atom[1])\n",
    "    remain_mask = ~ mask\n",
    "    return all_edge_index[:, remain_mask]\n",
    "\n",
    "\n",
    "def extend_bond(edge_index):\n",
    "    \"\"\"\n",
    "    extend bond edge to a next degree, i.e. consider all 1,3 interaction as bond\n",
    "    :param edge_index:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_edge = edge_index.size(-1)\n",
    "    source = edge_index[0]\n",
    "    target = edge_index[1]\n",
    "\n",
    "    # expand into a n*n matrix\n",
    "    source_expand = source.repeat(n_edge, 1)\n",
    "    target_t = target.view(-1, 1)\n",
    "\n",
    "    mask = (source_expand == target_t)\n",
    "    target_index_mapper = edge_index[1].repeat(n_edge, 1)\n",
    "    source_index_mapper = edge_index[0].repeat(n_edge, 1).t()\n",
    "\n",
    "    source_index = source_index_mapper[mask]\n",
    "    target_index = target_index_mapper[mask]\n",
    "\n",
    "    extended_bond = torch.cat([source_index.view(1, -1), target_index.view(1, -1)], dim=0)\n",
    "    # remove self to self interaction\n",
    "    extended_bond = extended_bond[:, source_index != target_index]\n",
    "    extended_bond = remove_bonding_edge(extended_bond, edge_index)\n",
    "    result = torch.cat([edge_index, extended_bond], dim=-1)\n",
    "\n",
    "    result = torch.unique(result, dim=1)\n",
    "    return result\n",
    "\n",
    "\n",
    "def name_extender(name, cal_3body_term=None, edge_version=None, cutoff=None, boundary_factor=None, use_center=None,\n",
    "                  bond_atom_sep=None, record_long_range=False, type_3_body='B', extended_bond=False, no_ext=False,\n",
    "                  geometry='QM'):\n",
    "    if extended_bond:\n",
    "        type_3_body = type_3_body + 'Ext'\n",
    "    name += '-' + type_3_body\n",
    "    if cal_3body_term:\n",
    "        name += 'msg'\n",
    "\n",
    "    if edge_version == 'cutoff':\n",
    "        if cutoff is None:\n",
    "            print('cutoff canot be None when edge version == cutoff, exiting...')\n",
    "            exit(-1)\n",
    "        name += '-cutoff-{:.2f}'.format(cutoff)\n",
    "    elif edge_version == 'voronoi':\n",
    "        name += '-box-{:.2f}'.format(boundary_factor)\n",
    "        if use_center:\n",
    "            name += '-centered'\n",
    "    else:\n",
    "        raise ValueError('Cannot recognize edge version(neither cutoff or voronoi), got {}'.format(edge_version))\n",
    "\n",
    "    if sort_edge:\n",
    "        name += '-sorted'\n",
    "\n",
    "    if bond_atom_sep:\n",
    "        name += '-defined_edge'\n",
    "\n",
    "    if record_long_range:\n",
    "        name += '-lr'\n",
    "\n",
    "    name += '-{}'.format(geometry)\n",
    "\n",
    "    if not no_ext:\n",
    "        name += '.pt'\n",
    "    return name\n",
    "\n",
    "\n",
    "sol_keys = [\"gasEnergy\", \"watEnergy\", \"octEnergy\", \"CalcSol\", \"CalcOct\", \"calcLogP\"]\n",
    "\n",
    "\n",
    "def my_pre_transform(data, edge_version, do_sort_edge, cal_efg, cutoff, boundary_factor, use_center, mol,\n",
    "                     cal_3body_term, bond_atom_sep, record_long_range, type_3_body='B', extended_bond=False):\n",
    "    \"\"\"\n",
    "    edge calculation\n",
    "    atom_edge_index is non-bonding edge idx_name when bond_atom_sep=True; Otherwise, it is bonding and non-bonding together\n",
    "    \"\"\"\n",
    "    edge_index = torch.zeros(2, 0).long()\n",
    "    dist, full_edge, _, _ = cal_edge(data.pos, [data.N], [0], edge_index, cal_coulomb=True, short_range=False)\n",
    "    dist = dist.cpu()\n",
    "    full_edge = full_edge.cpu()\n",
    "\n",
    "    if edge_version == 'cutoff':\n",
    "        data.BN_edge_index = full_edge[:, (dist < cutoff).view(-1)]\n",
    "    else:\n",
    "        data.BN_edge_index = voronoi_edge_index(data.pos, boundary_factor, use_center=use_center)\n",
    "\n",
    "    if record_long_range:\n",
    "        data.L_edge_index = remove_bonding_edge(full_edge, data.BN_edge_index)\n",
    "\n",
    "    '''\n",
    "    sort edge idx_name\n",
    "    '''\n",
    "    if do_sort_edge:\n",
    "        data.BN_edge_index = sort_edge(data.BN_edge_index)\n",
    "\n",
    "    '''\n",
    "    EFGs edge calculation\n",
    "    '''\n",
    "    if cal_efg:\n",
    "        if edge_version == 'cutoff':\n",
    "            dist, full_edge, _, _ = cal_edge(data.EFG_R, [data.EFG_N], [0], edge_index, cal_coulomb=True)\n",
    "            data.EFG_edge_index = full_edge[:, (dist < cutoff).view(-1)].cpu()\n",
    "        else:\n",
    "            data.EFG_edge_index = voronoi_edge_index(data.EFG_R, boundary_factor, use_center=use_center)\n",
    "\n",
    "        data.num_efg_edges = torch.LongTensor([data.EFG_edge_index.shape[-1]]).view(-1)\n",
    "\n",
    "    if bond_atom_sep:\n",
    "        '''\n",
    "        Calculate bonding edges and remove those non-bonding edges which overlap with bonding edge\n",
    "        '''\n",
    "        if mol is None:\n",
    "            print('rdkit mol file not given for molecule: {}, cannot calculate bonding edge, skipping this'.format(\n",
    "                data.Z))\n",
    "            return None\n",
    "        B_edge_index = mol_to_edge_index(mol)\n",
    "        if B_edge_index.numel() > 0 and B_edge_index.max() + 1 > data.N:\n",
    "            raise ValueError('problematic mol file: {}'.format(mol))\n",
    "        if B_edge_index.numel() > 0 and extended_bond:\n",
    "            B_edge_index = extend_bond(B_edge_index)\n",
    "        if B_edge_index.numel() > 0 and do_sort_edge:\n",
    "            B_edge_index = sort_edge(B_edge_index)\n",
    "        data.B_edge_index = B_edge_index\n",
    "        try:\n",
    "            data.N_edge_index = remove_bonding_edge(data.BN_edge_index, B_edge_index)\n",
    "        except Exception as e:\n",
    "            print(\"*\"*40)\n",
    "            print(\"BN: \", data.BN_edge_index)\n",
    "            print(\"B: \", data.B_edge_index)\n",
    "            from rdkit.Chem import MolToSmiles\n",
    "            print(\"SMILES: \", MolToSmiles(mol))\n",
    "            raise e\n",
    "        _edge_list = []\n",
    "        for bond_type in type_3_body:\n",
    "            _edge_list.append(getattr(data, bond_type + \"_edge_index\"))\n",
    "        _edge_index = torch.cat(_edge_list, dim=-1)\n",
    "    else:\n",
    "        _edge_index = data.BN_edge_index\n",
    "\n",
    "    '''\n",
    "    Calculate 3-atom term(Angle info)\n",
    "    It ls essentially an \"edge\" of edge\n",
    "    '''\n",
    "    if cal_3body_term:\n",
    "\n",
    "        atom_msg_edge_index = cal_msg_edge_index(_edge_index)\n",
    "        if do_sort_edge:\n",
    "            atom_msg_edge_index = sort_edge(atom_msg_edge_index)\n",
    "\n",
    "        setattr(data, type_3_body + '_msg_edge_index', atom_msg_edge_index)\n",
    "\n",
    "        setattr(data, 'num_' + type_3_body + '_msg_edge', torch.zeros(1).long() + atom_msg_edge_index.shape[-1])\n",
    "\n",
    "    for bond_type in ['B', 'N', 'L', 'BN']:\n",
    "        _edge_index = getattr(data, bond_type + '_edge_index', False)\n",
    "        if _edge_index is not False:\n",
    "            setattr(data, 'num_' + bond_type + '_edge', torch.zeros(1).long() + _edge_index.shape[-1])\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# ref = np.load(\"../../frag20-data/atomref.B3LYP_631Gd.10As.npz\")[\"atom_ref\"]\n",
    "\n",
    "def get_ref_energy(elements, ref):\n",
    "    return np.sum([ref[z][1] for z in elements]) * ev2hartree\n",
    "\n",
    "def extract_mol_by_confId(mol, confId):\n",
    "    mol_block = Chem.MolToMolBlock(mol, confId=confId)\n",
    "    mol = Chem.MolFromMolBlock(mol_block, removeHs=False)\n",
    "    return mol\n",
    "\n",
    "def generate_confs(smi, numConfs=1):\n",
    "    mol = Chem.MolFromSmiles(smi)\n",
    "    mol = AllChem.AddHs(mol)\n",
    "    # cids = AllChem.EmbedMultipleConfs(mol, numConfs=128, maxAttempts=1000, numThreads=8)\n",
    "    \n",
    "    ps = AllChem.ETKDG()\n",
    "    ps.maxAttempts = 1000\n",
    "    ps.randomSeed = 1\n",
    "    ps.pruneRmsThresh = 0.1\n",
    "    ps.numThreads = 0\n",
    "    cids = AllChem.EmbedMultipleConfs(mol, numConfs, ps)\n",
    "    \n",
    "    confs = []\n",
    "    for cid in cids:\n",
    "        mol_conf = extract_mol_by_confId(mol, cid)\n",
    "        confs.append(mol_conf)\n",
    "    return confs\n",
    "\n",
    "def optimize(mol):\n",
    "    mp = AllChem.MMFFGetMoleculeProperties(mol, mmffVariant='MMFF94')\n",
    "    ff = AllChem.MMFFGetMoleculeForceField(mol, mp, confId=0)\n",
    "    ff.Initialize()\n",
    "    ff.Minimize(maxIts=1000)\n",
    "    E = ff.CalcEnergy()\n",
    "    return E\n",
    "\n",
    "def get_low_energy_conf(smi, num_confs):\n",
    "    mol_confs = generate_confs(smi, num_confs)\n",
    "    data = []\n",
    "    for m in mol_confs:\n",
    "        E = optimize(m)\n",
    "        data.append([E, m])\n",
    "    sdata = sorted(data, key=lambda x: x[0])\n",
    "    low_energy, opt_conf = sdata[0]\n",
    "    mol_block = Chem.MolToMolBlock(opt_conf)\n",
    "    # print(mol_block)\n",
    "    pmol = pybel.readstring(\"mol\", mol_block)\n",
    "    return pmol\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b4ce9219-0a44-4e8d-9ff5-7545ee320659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "957d4f77-2932-414c-b7fe-7a4600813b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmaAmsGrad(torch.optim.Adam):\n",
    "    def __init__(self, training_model: torch.nn.Module, lr=1e-3, betas=(0.9, 0.99),\n",
    "                 eps=1e-8, weight_decay=0, ema=0.999, shadow_dict=None):\n",
    "        super().__init__(filter(lambda p: p.requires_grad, training_model.parameters()), lr, betas, eps, weight_decay, amsgrad=True)\n",
    "        # for initialization of shadow model\n",
    "        self.shadow_dict = shadow_dict\n",
    "        self.ema = ema\n",
    "        self.training_model = training_model\n",
    "\n",
    "        def avg_fn(averaged_model_parameter, model_parameter, num_averaged):\n",
    "            return ema * averaged_model_parameter + (1 - ema) * model_parameter\n",
    "\n",
    "        def avg_fn_deactivated(averaged_model_parameter, model_parameter, num_averaged):\n",
    "            return model_parameter\n",
    "\n",
    "        self.deactivated = (ema < 0)\n",
    "        self.shadow_model = AveragedModel(training_model, device=get_device(),\n",
    "                                          avg_fn=avg_fn_deactivated if self.deactivated else avg_fn)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        # t0 = time.time()\n",
    "\n",
    "        loss = super().step(closure)\n",
    "\n",
    "        # t0 = record_data('AMS grad', t0)\n",
    "        if self.shadow_model.n_averaged == 0 and self.shadow_dict is not None:\n",
    "            self.shadow_model.module.load_state_dict(self.shadow_dict, strict=False)\n",
    "            self.shadow_model.n_averaged += 1\n",
    "        else:\n",
    "            self.shadow_model.update_parameters(self.training_model)\n",
    "\n",
    "        # t0 = record_data('shadow update', t0)\n",
    "        return loss\n",
    "        \n",
    "\n",
    "def load_model(model_path):\n",
    "    floating_type = torch.double\n",
    "\n",
    "    net = PhysDimeNet( n_atom_embedding=95,\n",
    "                         modules=\"P-noOut P-noOut P\",\n",
    "                         bonding_type=\"BN BN BN\",\n",
    "                         n_feature=160,\n",
    "                         n_output=2,\n",
    "                         n_dime_before_residual=1,\n",
    "                         n_dime_after_residual=2,\n",
    "                         n_output_dense=3,\n",
    "                         n_phys_atomic_res=1,\n",
    "                         n_phys_interaction_res=1,\n",
    "                         n_phys_output_res=1,\n",
    "                         n_bi_linear=8,\n",
    "                         nh_lambda=0.01,\n",
    "                         normalize=True,\n",
    "                         shared_normalize_param=True,\n",
    "                         activations=\"ssp ssp ssp\",\n",
    "                         restrain_non_bond_pred=True,\n",
    "                         expansion_fn=\"(P_BN,P-noOut_BN):gaussian_64_10.0\",\n",
    "                         uncertainty_modify=\"none\",\n",
    "                         coulomb_charge_correct=False,\n",
    "                         loss_metric=\"mae\",\n",
    "                         uni_task_ss=False,\n",
    "                         lin_last=False,\n",
    "                         last_lin_bias=False,\n",
    "                         train_shift=True,\n",
    "                         mask_z=False,\n",
    "                         time_debug=False,\n",
    "                         z_loss_weight=0,\n",
    "                         acsf=False,\n",
    "                         energy_shift=1.0,\n",
    "                         energy_scale=2.0,\n",
    "                         debug_mode=False,\n",
    "                         action=\"names\",\n",
    "                         target_names=[\"gasEnergy\", \"waterEnergy\"],\n",
    "                         batch_norm=False,\n",
    "                         dropout=False,\n",
    "                         requires_atom_prop=False,\n",
    "                         requires_atom_embedding=True,\n",
    "                         pooling=\"sum\",\n",
    "                         ext_atom_features=None,\n",
    "                         ext_atom_dim=0)\n",
    "\n",
    "    # net = AveragedModel( net )\n",
    "    # state_dict = torch.load(model_path, map_location=get_device())\n",
    "    # net.load_state_dict(state_dict)\n",
    "    # net = net.to(get_device())\n",
    "\n",
    "    state_dict = torch.load(model_path, map_location=torch.device(\"cpu\"))\n",
    "    state_dict = fix_model_keys(state_dict)\n",
    "    incompatible_keys = net.load_state_dict(state_dict=state_dict, strict=False)\n",
    "    net = net.to(floating_type)\n",
    "    net = net.to(get_device())\n",
    "    return net\n",
    "\n",
    "\n",
    "model_path = \"../models/best_model.pt\"\n",
    "# model_path = \"qm_models/models/best_model.pt\"\n",
    "net = load_model( model_path )\n",
    "\n",
    "# for param in net.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# for param in net.main_module_list[1:].parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def loss_fn(output, ddG):\n",
    "    loss = F.l1_loss(output, ddG)\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def valid_fn(data_loader1, data_loader2, model):\n",
    "    model.eval()\n",
    "\n",
    "    trues, preds = [], []\n",
    "    for data1, ddG in zip(data_loader1, data_loader2):\n",
    "        data1 = data1.to(get_device())\n",
    "        ddG = ddG.to(get_device()).view(-1, 1).double()\n",
    "        \n",
    "        output = model(data1)[\"mol_prop\"][:, 1:]\n",
    "        preds.extend(output.view(-1).cpu().numpy().tolist())\n",
    "        trues.extend(ddG.view(-1).cpu().numpy().tolist())\n",
    "\n",
    "    all_mae = mean_absolute_error(trues, preds)\n",
    "    all_rmse = np.sqrt(mean_squared_error(trues, preds))\n",
    "    r2 = r2_score(trues, preds)\n",
    "    Rp= pearsonr(trues, preds)[0]\n",
    "    return Rp, r2, all_mae, all_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6754d2be-6fe3-48e5-a010-8730b28d0949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f38373b1-8b37-4d81-962b-b1966ba837e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(data, ddG, model, optimizer):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    data = data1.to(get_device())\n",
    "    ddG = ddG.to(get_device()).view(-1, 1).double()\n",
    "    output = model(data)[\"mol_prop\"][:, 1:]\n",
    "    \n",
    "    loss = loss_fn(output, ddG)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "693366d3-90f7-4571-a985-8e6cea5261f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_by_index(datas, indexs):\n",
    "    subset = []\n",
    "    for idx in indexs:\n",
    "        subset.append( datas[idx] )\n",
    "    return subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0851af46-f2a5-433c-b9d7-bfb80c66ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecb1714-24ea-49b7-a768-35f52d7f7218",
   "metadata": {},
   "source": [
    "# Predict Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "42816c54-c2c7-4b52-a83e-3e44672dc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "model_paths = glob.glob(\"models/submission_models/*.pt\")\n",
    "\n",
    "\n",
    "models = []\n",
    "for model_path in model_paths:\n",
    "    net = load_model( model_path )\n",
    "    net = net.eval()\n",
    "    models.append( net )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3ba26af8-b428-4b88-80e8-f429c197ea5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_model_fold5_k0.pt',\n",
       " 'best_model_fold2_k0.pt',\n",
       " 'best_model_fold6_k0.pt',\n",
       " 'best_model_fold4_k0.pt',\n",
       " 'best_model_fold1_k0.pt',\n",
       " 'best_model_fold3_k0.pt',\n",
       " 'best_model_fold9_k0.pt',\n",
       " 'best_model_fold0_k0.pt',\n",
       " 'best_model_fold8_k0.pt',\n",
       " 'best_model_fold7_k0.pt']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "778aa263-5aa1-4f31-8a89-70fc8937f8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict_ensemble(data_loader1, data_loader2, models):\n",
    "    trues, preds, stds = [], [], []\n",
    "    for data1, ddG in zip(data_loader1, data_loader2):\n",
    "        data1 = data1.to(get_device())\n",
    "        ddG = ddG.to(get_device()).view(-1, 1).double()\n",
    "\n",
    "        multiple_preds = []\n",
    "        for model in models:\n",
    "            # model.eval()\n",
    "            output = model(data1)[\"mol_prop\"][:, 1:]\n",
    "            multiple_preds.append(output.view(-1).cpu().item())\n",
    "        preds.append(np.mean(multiple_preds))\n",
    "        stds.append(np.std(multiple_preds))\n",
    "        trues.append(ddG.item())\n",
    "    return preds, trues, stds\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_ensemble_single(data1, models):\n",
    "    # print(data1)\n",
    "    pred, std = [], []\n",
    "    data1 = data1.to(get_device())\n",
    "   \n",
    "    multiple_preds = []\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        output = model(data1)[\"mol_prop\"][:, 1:]\n",
    "        multiple_preds.append(output.view(-1).cpu().item())\n",
    "    return multiple_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc0bb2f-55ff-43e8-b9d2-e3c7bd1f884f",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "56f1c4e3-a8f3-4ee0-b2fe-cadc9fbe487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"../data/clean_data/tox24_test_exclude_fragment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "eade3200-b4f4-45ae-979c-e5676f3cb5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>TTR binding activity</th>\n",
       "      <th>cSMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CC(OC1=C(C)C=C(Cl)C=C1)C(O)=O</td>\n",
       "      <td>70.6</td>\n",
       "      <td>Cc1cc(Cl)ccc1OC(C)C(=O)O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CC(C)=CCC/C(/C)=C/CO</td>\n",
       "      <td>49.0</td>\n",
       "      <td>CC(C)=CCC/C(C)=C/CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(CN1C[C@H](C)O[C@H](C)C1)CC2=CC=C(C=C2)C(C)(C)C</td>\n",
       "      <td>40.4</td>\n",
       "      <td>CC(Cc1ccc(C(C)(C)C)cc1)CN1C[C@@H](C)O[C@@H](C)C1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>COC1=CC=C(/C=C/C)C=C1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>C/C=C/c1ccc(OC)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CC(C)=CCC/C(/C)=C\\CO</td>\n",
       "      <td>84.9</td>\n",
       "      <td>CC(C)=CCC/C(C)=C\\CO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  TTR binding activity  \\\n",
       "0                      CC(OC1=C(C)C=C(Cl)C=C1)C(O)=O                  70.6   \n",
       "1                               CC(C)=CCC/C(/C)=C/CO                  49.0   \n",
       "2  CC(CN1C[C@H](C)O[C@H](C)C1)CC2=CC=C(C=C2)C(C)(C)C                  40.4   \n",
       "3                              COC1=CC=C(/C=C/C)C=C1                  25.4   \n",
       "4                               CC(C)=CCC/C(/C)=C\\CO                  84.9   \n",
       "\n",
       "                                            cSMILES  \n",
       "0                          Cc1cc(Cl)ccc1OC(C)C(=O)O  \n",
       "1                               CC(C)=CCC/C(C)=C/CO  \n",
       "2  CC(Cc1ccc(C(C)(C)C)cc1)CN1C[C@@H](C)O[C@@H](C)C1  \n",
       "3                                C/C=C/c1ccc(OC)cc1  \n",
       "4                               CC(C)=CCC/C(C)=C\\CO  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ce127fa-131d-418a-a0e9-8ecc0504805f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "af3543ff-cd8f-4c45-a791-0c85dcb5087a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[14:53:18] UFFTYPER: Warning: hybridization set to SP3 for atom 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O=[Si]=O\n",
      "270\n",
      "280\n",
      "c1ccc(B(c2ccccc2)c2ccccc2)cc1\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for idx, smi, exp, csmi in df_test.itertuples():\n",
    "    try:\n",
    "        pmol2 = get_low_energy_conf(csmi, num_confs=100)\n",
    "    except:\n",
    "        preds.append( np.nan )\n",
    "        continue\n",
    "    \n",
    "    coords2 = get_coords(pmol2)\n",
    "    elements2 = get_elements(pmol2)\n",
    "    \n",
    "    N2 = coords2.shape[0]\n",
    "    \n",
    "    this_data2 = Data(pos = torch.as_tensor(coords2, dtype=torch.double),\n",
    "                     Z = torch.as_tensor(elements2, dtype=torch.long),\n",
    "                     N = torch.as_tensor(N2, dtype=torch.long).view(-1),\n",
    "                     BN_edge_index_correct = torch.tensor([0], dtype=torch.long),\n",
    "                     batch=torch.tensor([0 for i in range(N2)], dtype=torch.long))\n",
    "    \n",
    "    nthis_data2 = my_pre_transform( this_data2, edge_version=\"cutoff\", do_sort_edge=True, cal_efg=False,\n",
    "                                   cutoff=10.0, boundary_factor=100., use_center=True, mol=None, cal_3body_term=False,\n",
    "                                   bond_atom_sep=False, record_long_range=True)\n",
    "  \n",
    "    multi_pred = predict_ensemble_single( nthis_data2, models )\n",
    "    preds.append( np.mean(multi_pred) ) \n",
    "    if idx % 10 == 0:\n",
    "        print( idx )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c7a034-dd57-41f3-ac88-d487b6ae5bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33970cc-29ba-48bf-b3cb-a1a80fa777b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
